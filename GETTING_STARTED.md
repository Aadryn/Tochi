# Guide de D√©marrage Rapide - LLM Proxy

## üéØ Objectif

Ce guide vous permet de d√©marrer rapidement avec le projet LLM Proxy.

## üìã Pr√©requis

- .NET 9 SDK ([Download](https://dotnet.microsoft.com/download/dotnet/9.0))
- Docker Desktop ([Download](https://www.docker.com/products/docker-desktop))
- Git
- Visual Studio 2022 / VS Code / Rider (optionnel)

## üöÄ D√©marrage Rapide (5 minutes)

### 1. Cloner le projet

```bash
git clone <repo-url>
cd LLMProxy
```

### 2. D√©marrer les d√©pendances avec Docker

```bash
docker-compose up -d postgres redis
```

Attendez que les services soient pr√™ts (environ 30 secondes).

### 3. Ex√©cuter les migrations de base de donn√©es

```bash
cd src/Infrastructure/LLMProxy.Infrastructure.PostgreSQL
dotnet ef migrations add InitialCreate
dotnet ef database update
```

### 4. Lancer le Gateway

```bash
cd ../../Presentation/LLMProxy.Gateway
dotnet run
```

Le Gateway sera accessible sur `http://localhost:5000`

### 5. (Optionnel) Lancer l'Admin API

Dans un nouveau terminal:

```bash
cd src/Presentation/LLMProxy.Admin.API
dotnet run
```

L'Admin API sera accessible sur `http://localhost:5001`

## üß™ Tester le Proxy

### Exemple de requ√™te simple

```bash
curl -X POST http://localhost:5000/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-api-key-here" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

### Exemple de streaming

```bash
curl -X POST http://localhost:5000/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-api-key-here" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Tell me a story"}],
    "stream": true
  }'
```

## üõ†Ô∏è D√©veloppement

### Restaurer les packages

```bash
dotnet restore
```

### Compiler le projet

```bash
dotnet build
```

### Ex√©cuter les tests

```bash
dotnet test
```

### Ex√©cuter les tests avec couverture

```bash
dotnet test /p:CollectCoverage=true /p:CoverletOutputFormat=opencover
```

## üê≥ Utilisation avec Docker Compose

Pour d√©marrer l'ensemble du stack (Gateway + Admin API + D√©pendances + Observabilit√©):

```bash
docker-compose up --build
```

Services disponibles:
- Gateway: http://localhost:8080
- Admin API: http://localhost:8081
- PostgreSQL: localhost:5432
- Redis: localhost:6379
- Jaeger UI: http://localhost:16686
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin)

## üìä Observabilit√©

### Jaeger (Tracing)
Acc√©dez √† http://localhost:16686 pour voir les traces distribu√©es.

### Prometheus (M√©triques)
Acc√©dez √† http://localhost:9090 pour requ√™ter les m√©triques.

### Grafana (Dashboards)
Acc√©dez √† http://localhost:3000 (admin/admin) pour visualiser les dashboards.

## üîß Configuration

### Configurer un nouveau provider LLM

√âditez `src/Presentation/LLMProxy.Gateway/appsettings.json`:

```json
{
  "ReverseProxy": {
    "Routes": {
      "my-provider-route": {
        "ClusterId": "my-provider-cluster",
        "Match": {
          "Path": "/my-provider/{**catch-all}"
        }
      }
    },
    "Clusters": {
      "my-provider-cluster": {
        "Destinations": {
          "destination1": {
            "Address": "https://api.myprovider.com"
          }
        }
      }
    }
  }
}
```

### Variables d'environnement

Cr√©ez un fichier `.env` √† la racine:

```env
ConnectionStrings__PostgreSQL=Host=localhost;Port=5432;Database=llmproxy;Username=postgres;Password=postgres
ConnectionStrings__Redis=localhost:6379
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
```

## üìù Prochaines √âtapes

1. **Impl√©menter les repositories manquants** (UserRepository, ApiKeyRepository, etc.)
2. **Cr√©er l'Admin API** avec endpoints CRUD pour g√©rer les tenants, users, providers
3. **Impl√©menter le service de quotas** avec Redis
4. **Ajouter le support de multiple providers** (Anthropic, Mistral, etc.)
5. **Configurer l'authentification OAuth2/JWT**
6. **Ajouter des tests d'int√©gration**
7. **Cr√©er le frontend React** pour l'administration

## üÜò D√©pannage

### Erreur de connexion PostgreSQL

V√©rifiez que PostgreSQL est d√©marr√©:
```bash
docker ps | grep postgres
```

Si non, d√©marrez-le:
```bash
docker-compose up -d postgres
```

### Erreur de connexion Redis

V√©rifiez que Redis est d√©marr√©:
```bash
docker ps | grep redis
```

### Port d√©j√† utilis√©

Changez le port dans `appsettings.json` ou utilisez:
```bash
dotnet run --urls "http://localhost:5555"
```

## üìö Documentation

- [Architecture](docs/architecture/README.md)
- [API Documentation](docs/api/README.md)
- [Configuration avanc√©e](docs/configuration/README.md)
- [D√©ploiement](docs/deployment/README.md)

## üí° Conseils

- Utilisez **TDD** : √©crivez les tests en premier (Red-Green-Refactor)
- Respectez **SOLID** : chaque classe a une seule responsabilit√©
- Appliquez **YAGNI** : n'impl√©mentez que ce qui est n√©cessaire maintenant
- Gardez **KISS** : la simplicit√© est la cl√©
- √âvitez **DRY** : ne vous r√©p√©tez pas

## üìû Support

Pour toute question ou probl√®me, ouvrez une issue sur GitHub.
