# T√¢che 086 - Ajouter propri√©t√© MaxContextLength √† LLMModel

## PRIORIT√â
üî¥ **P1 - CRITIQUE** (9 erreurs de build)

## OBJECTIF

Ajouter la propri√©t√© `MaxContextLength` √† l'entit√© `LLMModel` pour r√©soudre 9 erreurs de compilation dans les providers.

## CONTEXTE

### √âtat Actuel

**Erreurs de build :**
- `CohereProviderClient.cs` : 2 erreurs (lignes 85, 96)
- `GoogleGeminiProviderClient.cs` : 3 erreurs (lignes 90, 102, 114)
- `HuggingFaceProviderClient.cs` : 4 erreurs (lignes 83, 92, 101, 110)

**Message d'erreur :**
```
error CS0117: 'LLMModel' does not contain a definition for 'MaxContextLength'
```

**Fichiers affect√©s :**
- `CohereProviderClient.cs` utilise `model.MaxContextLength` (2 occurrences)
- `GoogleGeminiProviderClient.cs` utilise `model.MaxContextLength` (3 occurrences)
- `HuggingFaceProviderClient.cs` utilise `model.MaxContextLength` (4 occurrences)

### Fichier √† Modifier

**Fichier :** `applications/proxy/backend/src/Core/LLMProxy.Domain/LLM/LLMModel.cs`

**Localisation :** Chercher le fichier LLMModel dans le domaine

## IMPL√âMENTATION

### √âtape 1 : Localiser LLMModel.cs

```bash
find /workspaces/proxy/applications/proxy/backend/src/Core -name "LLMModel.cs"
```

### √âtape 2 : Analyser la Structure

Lire le fichier pour comprendre :
- Structure actuelle de la classe
- Propri√©t√©s existantes
- Pattern de nommage (PascalCase, documentation XML)

### √âtape 3 : Ajouter MaxContextLength

Ajouter la propri√©t√© avec documentation XML :

```csharp
/// <summary>
/// Longueur maximale du contexte en tokens.
/// </summary>
/// <remarks>
/// <para>
/// D√©termine le nombre maximum de tokens (input + output) que le mod√®le peut traiter.
/// </para>
/// <para>
/// <b>Exemples de valeurs typiques :</b>
/// <list type="bullet">
/// <item><c>4096</c> - GPT-3.5-turbo</item>
/// <item><c>8192</c> - GPT-4</item>
/// <item><c>32768</c> - GPT-4-32k</item>
/// <item><c>128000</c> - GPT-4-turbo, Claude-3</item>
/// <item><c>200000</c> - Claude-3.5-sonnet</item>
/// <item><c>1000000</c> - Gemini-1.5-pro</item>
/// </list>
/// </para>
/// </remarks>
/// <example>4096, 8192, 32768, 128000</example>
public int? MaxContextLength { get; private set; }
```

### √âtape 4 : Mettre √† Jour le Constructeur/Factory

Si `LLMModel` a un constructeur ou une m√©thode factory `Create()`, ajouter le param√®tre :

```csharp
public static LLMModel Create(
    string name,
    string provider,
    // ... autres param√®tres existants
    int? maxContextLength = null)
{
    return new LLMModel
    {
        // ... propri√©t√©s existantes
        MaxContextLength = maxContextLength
    };
}
```

### √âtape 5 : V√©rifier les Tests

Chercher les tests unitaires de LLMModel :

```bash
find /workspaces/proxy/applications/proxy/backend/tests -name "*LLMModel*Tests.cs"
```

Mettre √† jour les tests si n√©cessaire.

## CRIT√àRES DE SUCC√àS

- [ ] Propri√©t√© `MaxContextLength` ajout√©e √† `LLMModel`
- [ ] Documentation XML compl√®te et en fran√ßais
- [ ] Build Proxy Backend : 0 erreurs (9 erreurs r√©solues)
- [ ] Build Proxy Backend : 0 warnings
- [ ] Tests LLMModel passent (si existants)
- [ ] Conformit√© ADR-001 (d√©j√† 1 type par fichier)

## VALIDATION

### Build
```bash
cd /workspaces/proxy/applications/proxy/backend
dotnet build --no-restore
# Attendu: 4 erreurs restantes (TokenUsage), 0 warning
```

### Tests
```bash
cd /workspaces/proxy/applications/proxy/backend
dotnet test --no-build --filter "FullyQualifiedName~LLMModel"
# Attendu: Tous les tests LLMModel passent
```

## ESTIMATION

**Effort** : 30 minutes

## R√âF√âRENCES

- ADR-001 : Un seul type par fichier C#
- ADR-014 : DDD Value Objects et Entities
- Fichiers sources des erreurs :
  - `CohereProviderClient.cs`
  - `GoogleGeminiProviderClient.cs`
  - `HuggingFaceProviderClient.cs`

## NOTES

Cette propri√©t√© est d√©j√† utilis√©e dans 3 providers, indiquant qu'elle a probablement √©t√© supprim√©e accidentellement lors d'un refactoring pr√©c√©dent.
